{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test for People detection using AlexNet + FC regression model\n",
    "#Network will output yes or no and bounding box for detection\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in all inputs\n",
    "#input images and bounding boxes\n",
    "image_files = os.listdir('images')\n",
    "labels = os.listdir('xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#Lets see a random image\n",
    "#random.seed(23)\n",
    "#index = random.randint(0, len(image_files))\n",
    "index = 3763\n",
    "img = cv2.imread(os.path.join('images',image_files[index]),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2290c8a4940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2290a081e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Will use matplotlib for showing the image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Plot inline\n",
    "%matplotlib inline\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 7 7 31 32\n"
     ]
    }
   ],
   "source": [
    "#Lets take a look at bounding box label\n",
    "xml_file = os.path.join('xml',labels[index])\n",
    "label_file = open(xml_file , 'r')\n",
    "lines = label_file.read()\n",
    "print(lines)\n",
    "label_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2290c923978>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2290c8ce198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The format of the label file is 0 x x x x if nothing is present in the image and 1 x0 y0 x1 y1 if there is an object present\n",
    "#Lets use re to get the coordinates and plot the image\n",
    "import re\n",
    "pattern = re.compile(r\"(\\d+) (\\d+) (\\d+) (\\d+) (\\d+)\")\n",
    "matchObj = pattern.findall(lines)\n",
    "if matchObj:\n",
    "    is_present = int(matchObj[0][0])\n",
    "    if is_present == 1:\n",
    "        x0 = int(matchObj[0][1])\n",
    "        y0 = int(matchObj[0][2])\n",
    "        x1 = int(matchObj[0][3])\n",
    "        y1 = int(matchObj[0][4])\n",
    "        cv2.rectangle(img,(x0,y0),(x1,y1),(255,0,0),2)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5880\n",
      "5880\n"
     ]
    }
   ],
   "source": [
    "#Lets us look at total images\n",
    "print(len(image_files))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5880, 49, 49, 3)\n"
     ]
    }
   ],
   "source": [
    "#Read all these and populate np array\n",
    "#Read images\n",
    "allImage = np.zeros([len(image_files),49,49,3])\n",
    "for i in range(0,len(image_files)):\n",
    "    img = cv2.imread(os.path.join('images',image_files[i]),1)\n",
    "    allImage[i]=img\n",
    "print(allImage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5880, 6)\n"
     ]
    }
   ],
   "source": [
    "#Read labels and convert to one hot encoded\n",
    "all_labels = np.zeros([len(labels),6])\n",
    "import re\n",
    "for i in range(0,len(labels)):\n",
    "    label_file = open(os.path.join('xml',labels[i]) , 'r')\n",
    "    lines = label_file.read()\n",
    "    label_file.close()\n",
    "    pattern = re.compile(r\"(\\d+) (\\d+) (\\d+) (\\d+) (\\d+)\")\n",
    "    matchObj = pattern.findall(lines)\n",
    "    if matchObj:\n",
    "        is_present = int(matchObj[0][0])\n",
    "        if is_present == 1:\n",
    "            not_present = 0\n",
    "            present = 1            \n",
    "            x0 = int(matchObj[0][1])\n",
    "            y0 = int(matchObj[0][2])\n",
    "            x1 = int(matchObj[0][3])\n",
    "            y1 = int(matchObj[0][4])\n",
    "        else:\n",
    "            not_present = 1\n",
    "            present = 0        \n",
    "            x0 = 0\n",
    "            y0 = 0\n",
    "            x1 = 0\n",
    "            y1 = 0\n",
    "    all_labels[i] = [not_present,present,x0,y0,x1,y1]\n",
    "print(all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test validation split + randomize order\n",
    "tf.random_shuffle(allImage, seed=181)\n",
    "tf.random_shuffle(all_labels, seed=181)\n",
    "import sklearn.model_selection as sk\n",
    "\n",
    "X_train, X_test, y_train, y_test = sk.train_test_split(allImage,all_labels,test_size=0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4704\n",
      "4704\n",
      "1176\n",
      "1176\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are approximate 3000 negatives and 2880 positive images. The images are taken from a 640x480 image and cropped with a 8\n",
    "#pixel sliding window. If the bounding box is completely encompassed in the 49x49 frame it is stored as label for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 23, 23, 48)\n",
      "(?, 9, 9, 128)\n",
      "(?, 7, 7, 192)\n",
      "(?, 5, 5, 192)\n",
      "(?, 1, 1, 128)\n",
      "(?, 2048)\n",
      "(?, 2048)\n",
      "(?, 6)\n"
     ]
    }
   ],
   "source": [
    "#Setup tensorflow\n",
    "\n",
    "#Setup inputs\n",
    "x = tf.placeholder(\"float\", [None, 49, 49, 3], name='x')#Image\n",
    "y = tf.placeholder(\"float\", [None, 6], name='y')#Label and boundingbox\n",
    "\n",
    "#Setup network, using AlexNet as reference with minor changes in first and last layers\n",
    "\n",
    "############################Layer 1\n",
    "weight_1 = tf.Variable(tf.truncated_normal([3, 3, 3, 48]))#Kernal size changed from 11 to 3 and stride from 4 to 1        \n",
    "bias_1 = tf.Variable(tf.zeros(48))\n",
    "\n",
    "#Apply convolution\n",
    "conv_layer_1 = tf.nn.conv2d(x, weight_1, strides=[1,1,1,1], padding='VALID')\n",
    "# Add bias\n",
    "conv_layer_1 = tf.nn.bias_add(conv_layer_1, bias_1)\n",
    "\n",
    "# Apply activation function\n",
    "conv_layer_1 = tf.nn.relu(conv_layer_1)      \n",
    "conv_layer_1 = tf.nn.max_pool(conv_layer_1,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "print(conv_layer_1.get_shape())\n",
    "#############################Layer 2\n",
    "weight_2 = tf.Variable(tf.truncated_normal([5, 5, 48, 128]))\n",
    "bias_2 = tf.Variable(tf.zeros(128))\n",
    "\n",
    "#Apply convolution\n",
    "conv_layer_2 = tf.nn.conv2d(conv_layer_1, weight_2, strides=[1,1,1,1], padding='VALID')\n",
    "# Add bias\n",
    "conv_layer_2 = tf.nn.bias_add(conv_layer_2, bias_2)\n",
    "\n",
    "# Apply activation function\n",
    "conv_layer_2 = tf.nn.relu(conv_layer_2)      \n",
    "conv_layer_2 = tf.nn.max_pool(conv_layer_2,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "print(conv_layer_2.get_shape())\n",
    "#############################Layer 3\n",
    "weight_3 = tf.Variable(tf.truncated_normal([3, 3, 128, 192]))\n",
    "bias_3 = tf.Variable(tf.zeros(192))\n",
    "\n",
    "#Apply convolution\n",
    "conv_layer_3 = tf.nn.conv2d(conv_layer_2, weight_3, strides=[1,1,1,1], padding='VALID')\n",
    "# Add bias\n",
    "conv_layer_3 = tf.nn.bias_add(conv_layer_3, bias_3)\n",
    "# Apply activation function\n",
    "conv_layer_3 = tf.nn.relu(conv_layer_3)      \n",
    "\n",
    "print(conv_layer_3.get_shape())\n",
    "\n",
    "weight_4 = tf.Variable(tf.truncated_normal([3, 3, 192, 192]))\n",
    "bias_4 = tf.Variable(tf.zeros(192))\n",
    "\n",
    "#Apply convolution\n",
    "conv_layer_3 = tf.nn.conv2d(conv_layer_3, weight_4, strides=[1,1,1,1], padding='VALID')\n",
    "# Add bias\n",
    "conv_layer_3 = tf.nn.bias_add(conv_layer_3, bias_4)\n",
    "# Apply activation function\n",
    "conv_layer_3 = tf.nn.relu(conv_layer_3)      \n",
    "\n",
    "print(conv_layer_3.get_shape())\n",
    "\n",
    "weight_5 = tf.Variable(tf.truncated_normal([3, 3, 192, 128]))\n",
    "bias_5 = tf.Variable(tf.zeros(128))\n",
    "\n",
    "#Apply convolution\n",
    "conv_layer_3 = tf.nn.conv2d(conv_layer_3, weight_5, strides=[1,1,1,1], padding='VALID')\n",
    "# Add bias\n",
    "conv_layer_3 = tf.nn.bias_add(conv_layer_3, bias_5)\n",
    "# Apply activation function\n",
    "conv_layer_3 = tf.nn.relu(conv_layer_3)  \n",
    "\n",
    "conv_layer_3 = tf.nn.max_pool(conv_layer_3,ksize=[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "\n",
    "print(conv_layer_3.get_shape())\n",
    "#############################Layer 4\n",
    "dim = conv_layer_3.get_shape().as_list()  \n",
    "fc_1 = tf.reshape(conv_layer_3, [-1,dim[1]*dim[2]*dim[3]])     \n",
    "\n",
    "dim = fc_1.get_shape().as_list()  \n",
    "fc_weight_1 = tf.Variable(tf.truncated_normal([dim[1], 2048]))        \n",
    "fc_bias_1 = tf.Variable(tf.zeros(2048))\n",
    "    \n",
    "# Apply multiplication        \n",
    "fc_layer_1 = tf.matmul(fc_1, fc_weight_1)\n",
    "# Add bias\n",
    "fc_layer_1 = tf.nn.bias_add(fc_layer_1, fc_bias_1)\n",
    "# Apply activation function\n",
    "fc_layer_1 = tf.nn.relu(fc_layer_1)          \n",
    "\n",
    "print(fc_layer_1.get_shape())\n",
    "#############################Layer 5\n",
    "dim = fc_layer_1.get_shape().as_list()  \n",
    "fc_weight_2 = tf.Variable(tf.truncated_normal([dim[1], 2048]))        \n",
    "fc_bias_2 = tf.Variable(tf.zeros(2048))\n",
    "    \n",
    "# Apply multiplication        \n",
    "fc_layer_2 = tf.matmul(fc_layer_1, fc_weight_2)\n",
    "# Add bias\n",
    "fc_layer_2 = tf.nn.bias_add(fc_layer_2, fc_bias_2)\n",
    "# Apply activation function\n",
    "fc_layer_2 = tf.nn.relu(fc_layer_2)          \n",
    "\n",
    "print(fc_layer_2.get_shape())\n",
    "#############################Layer 6\n",
    "#Output label and bounding box\n",
    "dim = fc_layer_2.get_shape().as_list()  \n",
    "fc_weight_3 = tf.Variable(tf.truncated_normal([dim[1], 6]))        \n",
    "fc_bias_3 = tf.Variable(tf.zeros(6))\n",
    "# Apply multiplication        \n",
    "fc_layer_3 = tf.matmul(fc_layer_2, fc_weight_3)\n",
    "# Add bias\n",
    "output_layer = tf.nn.bias_add(fc_layer_3, fc_bias_3)\n",
    "\n",
    "print(output_layer.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2)\n",
      "(?, 4)\n",
      "(?, 4)\n"
     ]
    }
   ],
   "source": [
    "#define loss\n",
    "is_present = output_layer[:,0:2] \n",
    "bounding_box_coordinates = output_layer[:,2:]\n",
    "print(is_present.get_shape())\n",
    "print(bounding_box_coordinates.get_shape())\n",
    "print(y[:,2:].get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_overlap_iou(bboxes1, bboxes2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        bboxes1: shape (total_bboxes1, 4)\n",
    "            with x1, y1, x2, y2 point order.\n",
    "        bboxes2: shape (total_bboxes2, 4)\n",
    "            with x1, y1, x2, y2 point order.\n",
    "        p1 *-----\n",
    "           |     |\n",
    "           |_____* p2\n",
    "    Returns:\n",
    "        Tensor with shape (total_bboxes1, total_bboxes2)\n",
    "        with the IoU (intersection over union) of bboxes1[i] and bboxes2[j]\n",
    "        in [i, j].\n",
    "    \"\"\"\n",
    "\n",
    "    x11 = bboxes1[:,0]\n",
    "    y11 = bboxes1[:,1]\n",
    "    x12 = bboxes1[:,2]\n",
    "    y12 = bboxes1[:,3]\n",
    "    \n",
    "    x21 = bboxes2[:,0]\n",
    "    y21 = bboxes2[:,1]\n",
    "    x22 = bboxes2[:,2]\n",
    "    y22 = bboxes2[:,3]\n",
    "\n",
    "    #x11, y11, x12, y12 = tf.split(bboxes1, 4, axis=1)\n",
    "    #x21, y21, x22, y22 = tf.split(bboxes2, 4, axis=1)\n",
    "\n",
    "    xI1 = tf.maximum(x11, x21)\n",
    "    yI1 = tf.maximum(y11, y21)\n",
    "\n",
    "    xI2 = tf.minimum(x12, x22)\n",
    "    yI2 = tf.minimum(y12, y22)\n",
    "\n",
    "    inter_area = (xI2 - xI1 + 1) * (yI2 - yI1 + 1)\n",
    "\n",
    "    bboxes1_area = (x12 - x11 + 1) * (y12 - y11 + 1)\n",
    "    bboxes2_area = (x22 - x21 + 1) * (y22 - y21 + 1)\n",
    "\n",
    "    union = (bboxes1_area + tf.transpose(bboxes2_area)) - inter_area\n",
    "\n",
    "    return tf.maximum(inter_area / union, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dim = is_prediction_present.get_shape().as_list() \n",
    "#l1 = tf.constant(0,shape=[dim[0], 1])\n",
    "#l0 = tf.mult(bbox_loss,0)\n",
    "#print(l0.get_shape())\n",
    "#print(l1.get_shape())\n",
    "#b = tf.cond(is_prediction_present, lambda: tf.constant(10), lambda: tf.constant(0))\n",
    "#iou_loss = tf.cond(prediction[:,0] < prediction[:,1], lambda: bbox_overlap_iou(bounding_box_coordinates,y[:,1:]), lambda: 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?,)\n",
      "(?,)\n",
      "(?,)\n"
     ]
    }
   ],
   "source": [
    "#calculate cross entropy loss\n",
    "cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=is_present, labels=y[:,:2]))\n",
    "\n",
    "#calculate loss only is prediction says person is present 2nd column > 1st column\n",
    "prediction = tf.nn.softmax(is_present)\n",
    "is_prediction_present = tf.less_equal(prediction[:,0],prediction[:,1])    \n",
    "print(is_prediction_present.get_shape())\n",
    "\n",
    "bbox_loss = bbox_overlap_iou(bounding_box_coordinates,y[:,1:])\n",
    "print(bbox_loss.get_shape())\n",
    "\n",
    "l0 = tf.zeros_like(bbox_loss)\n",
    "print(l0.get_shape())\n",
    "\n",
    "#if prediction is present calculate iou loss, else return 0\n",
    "iou_loss = tf.reduce_mean(tf.where(is_prediction_present,bbox_loss,l0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add weights to cross entropy and iou losses\n",
    "\n",
    "alpha = 1.0\n",
    "total_loss = alpha * cross_entropy_loss + (1 - alpha) * iou_loss\n",
    "optimizer = tf.train.AdamOptimizer().minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(is_present, 1), tf.argmax(y[:,:2], 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer,feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "                x: feature_batch,\n",
    "                y: label_batch})\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, valid_features, valid_labels, total_loss, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(total_loss, feed_dict={\n",
    "                       x: feature_batch,\n",
    "                       y: label_batch})\n",
    "    acc = session.run(accuracy, feed_dict={\n",
    "                       x: valid_features,\n",
    "                       y: valid_labels})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss,acc))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 511\n",
      "512 1023\n",
      "1024 1535\n",
      "1536 2047\n",
      "2048 2559\n",
      "2560 3071\n",
      "3072 3583\n",
      "3584 4095\n",
      "4096 4607\n",
      "4608 4704\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, int(np.ceil(len(X_train)/batch_size))):\n",
    "    start_index = i*batch_size\n",
    "    end_index = min(i*batch_size+(batch_size-1),len(X_train))\n",
    "    print(start_index,end_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 0:  Loss:        nan Validation Accuracy: 0.478741\n",
      "Epoch  1, Batch 1:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  1, Batch 2:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  1, Batch 3:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  1, Batch 4:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  1, Batch 5:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  1, Batch 6:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  1, Batch 7:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  1, Batch 8:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  1, Batch 9:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  2, Batch 0:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  2, Batch 1:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  2, Batch 2:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  2, Batch 3:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  2, Batch 4:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  2, Batch 5:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  2, Batch 6:  Loss:        nan Validation Accuracy: 0.521259\n",
      "Epoch  2, Batch 7:  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-3cf16d47b708>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mtrain_neural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epoch {:>2}, Batch {}:  '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mprint_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-51-88aed88ec258>\u001b[0m in \u001b[0;36mprint_stats\u001b[1;34m(session, feature_batch, label_batch, valid_features, valid_labels, total_loss, accuracy)\u001b[0m\n\u001b[0;32m     14\u001b[0m     acc = session.run(accuracy, feed_dict={\n\u001b[0;32m     15\u001b[0m                        \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalid_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                        y: valid_labels})\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss: {:>10.4f} Validation Accuracy: {:.6f}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, int(np.ceil(len(X_train)/batch_size))):\n",
    "        start_index = i*batch_size\n",
    "        end_index = min(i*batch_size+(batch_size-1),len(X_train))\n",
    "        batch_features = X_train[start_index:end_index]\n",
    "        batch_labels = y_train[start_index:end_index]            \n",
    "        train_neural_network(sess, optimizer, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, Batch {}:  '.format(epoch + 1, i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, X_test, y_test, total_loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
